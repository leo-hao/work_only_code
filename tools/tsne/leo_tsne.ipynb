{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "from mmcv import Config\n",
    "from mmseg.apis import inference_segmentor, init_segmentor\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mmseg.datasets import build_dataloader, build_dataset\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the segmentor\n",
    "cfg = Config.fromfile('configs/segformer/segformer_mit-b0_8x1_1024x1024_160k_cityscapes.py')\n",
    "checkpoint_file = 'checkpoint/segformer_mit-b0_8x1_1024x1024_160k_cityscapes_20211208_101857-e7f88502.pth'\n",
    "model = init_segmentor(cfg, checkpoint_file, device='cuda:0')\n",
    "\n",
    "# load the dataset\n",
    "data_dir = 'data/cityscapes/leftImg8bit/train'\n",
    "#img_infos = mmcv.scan_images(data_dir, recursive=True)\n",
    "#dataset = build_dataset(cfg.data.train)\n",
    "dataset = build_dataset(cfg.data.val)#改为验证集后，就不会裁剪了，那个encode_decode的尺寸会是原尺寸（1，19，1024，2048）\n",
    "dataloader = build_dataloader(\n",
    "    dataset,\n",
    "    samples_per_gpu=1,\n",
    "    workers_per_gpu=1,\n",
    "    dist=False,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
    "model.eval()\n",
    "features = {}\n",
    "targets = {}\n",
    "model.to(device)\n",
    "feat_maps = np.empty([0, 19,1024,1024])\n",
    "for i, data in enumerate(dataloader):\n",
    "  #if i == 1:\n",
    "  #  break\n",
    "  img_metas = data['img_metas'].data\n",
    "  images = data['img'].data[0].to(device)\n",
    "  #print(images.shape)#torch.Size([1, 3, 1024, 1024])\n",
    "  #target = data['gt_semantic_seg'].data[0].to(device)\n",
    "  #print(target)\n",
    "  #print(target.shape)#torch.Size([1, 1, 1024, 1024])\n",
    "  #img_path = data['img_metas'].data[0][0].get('filename')\n",
    "  #feat = model.extract_feat(images)\n",
    "  feat_map = model.encode_decode(images, img_metas)\n",
    "  #feat_map = out.squeeze()\n",
    "  \n",
    "  feat_map = feat_map.cpu().detach().numpy()\n",
    "  #feat_map = (feat_map - np.mean(feat_map, axis=0)) / np.std(feat_map,axis=0)\n",
    "  #feat_map = feat_map.reshape(19,-1)\n",
    "  feat_maps = np.append(feat_maps, feat_map, axis=0)\n",
    "  #print(\"out.shape:\", out.shape)#out.shape: torch.Size([1, 19, 1024, 1024])\n",
    "  #print(\"out:\", out)\n",
    "\n",
    "  #print('feat[0].shape:',feat[0].shape)#feat[0].shape: torch.Size([1, 32, 256, 256])\n",
    "  #print('feat[1].shape:',feat[1].shape)#feat[1].shape: torch.Size([1, 64, 128, 128])\n",
    "  #print('feat[2].shape:',feat[2].shape)#feat[2].shape: torch.Size([1, 160, 64, 64])\n",
    "  #print('feat[3].shape:',feat[3].shape)#feat[3].shape: torch.Size([1, 256, 32, 32])\n",
    "  #print(model.num_classes)\n",
    "  #output = inference_segmentor(model, img_path)\n",
    "  #print(output)\n",
    "  #result_flat = output[0].flatten()\n",
    "\n",
    "  # tsne = TSNE(n_components=2, random_state=0)\n",
    "  # result_tsne = tsne.fit_transform(result_flat.reshape(-1, 1))\n",
    "  # plt.scatter(result_tsne[:, 0], result_tsne[:, 1], c=result_flat, cmap='tab20')\n",
    "  # plt.show()\n",
    "  #print(output[0].shape)#(1024, 2048)\n",
    "  #print(features['train'].shape)\n",
    "  #features['train'] = np.append(features['train'],output[0], axis=0)\n",
    "  #targets['train'] = np.append(targets['train'],target.cpu(), axis=0)\n",
    "  #print(features['train'].shape)\n",
    "  if i == 200:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "tsne = TSNE(n_components=2,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in range(19):\n",
    "    features = feat_maps[:,label,:,:]\n",
    "    flatten_feat =[]\n",
    "    for f in features:\n",
    "        flatten_feat.append(f.reshape(-1))\n",
    "    X = np.array(flatten_feat)\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    pca_50 = PCA(n_components=32)\n",
    "\n",
    "    pca_result_50 = pca_50.fit_transform(X)\n",
    "    X_tsne = tsne.fit_transform(pca_result_50)\n",
    "\n",
    "    data.append((X_tsne, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PALETTE = np.array([[128, 64, 128], [244, 35, 232], [70, 70, 70], [102, 102, 156],\n",
    "            [190, 153, 153], [153, 153, 153], [250, 170, 30], [220, 220, 0],\n",
    "            [107, 142, 35], [152, 251, 152], [70, 130, 180], [220, 20, 60],\n",
    "            [255, 0, 0], [0, 0, 142], [0, 0, 70], [0, 60, 100],\n",
    "            [0, 80, 100], [0, 0, 230], [119, 11, 32]])\n",
    "colors  = ['#%02x%02x%02x' % (r,g,b) for r,g,b in PALETTE]\n",
    "\n",
    "for X_tsne, label in data:\n",
    "    label_color = colors[label]\n",
    "    plt.scatter(X_tsne[:,0], X_tsne[:,1], c=label_color)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
